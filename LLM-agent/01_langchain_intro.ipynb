{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75245334",
   "metadata": {},
   "source": [
    "# Langchain Intro \n",
    "`01_langchain_intro.ipynb`\n",
    "\n",
    "- LLM powerd 어플리케이션 제작을 위한 프레임 워크 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37e2b236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4270e2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CAraStDlpDdrn0njrFxIXJKQfoErC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4110e19e-e69c-4d7b-9034-a44dba7aa946-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model= 'gpt-4.1-nano')\n",
    "llm.invoke(\"Hello, world!\") #sklean 에서 fit 했던 것처럼 계속 나오는'invoke: llm 을 불러온다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cd07abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가, 외국어로 메세지가 들어오면, 한국어로 번력해주는 AI 를 만들고 싶다면? \n",
    "msg= input('외국어를 넣으세요')\n",
    "res = llm.invoke(f'한국어로 번역해줘:  {msg}')\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7028cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Andiamo a pranzare. Cosa mangiamo?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 47, 'total_tokens': 59, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CAraa5FvU6GUjS8lAZYiQBla0DNE0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e635a399-9cce-4862-9315-59f71bbd3193-0', usage_metadata={'input_tokens': 47, 'output_tokens': 12, 'total_tokens': 59, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "massages =[\n",
    "    #채팅 세션의 전체적인 안내사항 \n",
    "    SystemMessage(content='너는 훌룡한 조수야. 한국어를 이탈리아어로 번역해라'),\n",
    "    HumanMessage(content = '점심을 먹자. 뭘먹을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(massages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3fde1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sono sazio.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 38, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CArab9T8VslIgHeFREEqP24oIIWKc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--215bf584-995d-4639-aaf9-7484dbb5636d-0', usage_metadata={'input_tokens': 38, 'output_tokens': 4, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "massages =[\n",
    "    #채팅 세션의 전체적인 안내사항 \n",
    "    {'role': 'system', 'content':'너는 훌룡한 조수야. 한국어를 이탈리아어로 번역해라'},\n",
    "    {'role': 'human', 'content': '배부르다'},\n",
    "    \n",
    "]\n",
    "\n",
    "llm.invoke(massages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e38e68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Sono| sa|zio|.||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(massages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4a3931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시리얼라이징과 파싱 \n",
    "#runnable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fddd6e8",
   "metadata": {},
   "source": [
    "## Prompt Template \n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법 \n",
    "\n",
    "## Chain \n",
    "- Langchain의 각 구성요소를 묶어서(chaining) 한번에 실행(invoke)할 수 있도록 하는 기능 \n",
    "- `a| b | c` 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법(LCEL LanChain Expression Language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d99be4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='独島は韓国の領土です。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 25, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CAracdXSgX72bUTOw7YkH61Qh1joa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5ab43875-d7c2-44fd-ac6e-1867486b683e-0', usage_metadata={'input_tokens': 25, 'output_tokens': 10, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages= [\n",
    "    {'role': 'system', 'content':'Tranxlate Korean to{lang}'},\n",
    "    {'role': 'human', 'content': '{text}'}\n",
    "    \n",
    "\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '독도는 한국땅'}) \n",
    "prompt.to_messages()\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bf32621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='独島は韓国の領土です。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 25, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CAracvYAVS3hYAlYEVT9cbJHPhifT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--346ee337-8342-4e6e-8bcc-e25d41fec183-0', usage_metadata={'input_tokens': 25, 'output_tokens': 10, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptompt = prompt_template.invoke({'lang':'영어', 'text': '버거가 먹고 싶다'})\n",
    "llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53db0c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat kimchi stew.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅을 할 경우에는 챗프롬프트\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# a | b | c\n",
    "chain = prompt_template | llm | Output_parser\n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌개가 먹고싶다'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "218bb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 전반기 매출 분석을 위해 단계별로 진행할 수 있는 EDA(탐색적 데이터 분석) 절차를 아래와 같이 나누어 제시하겠습니다.\n",
      "\n",
      "1. 데이터 수집 및 준비\n",
      "   - 매출 데이터 수집: 2025년 1월 ~ 6월까지의 매출 데이터 확보\n",
      "   - 데이터 소스 파악: 내부 시스템, ERP, POS 시스템 등\n",
      "   - 데이터 형식 확인: CSV, Excel, 데이터베이스 등\n",
      "2. 데이터 전처리\n",
      "   - 결측치 및 이상치 검토 및 처리\n",
      "   - 데이터 타입 통합 및 정제 (날짜, 숫자, 텍스트 등)\n",
      "   - 날짜 형식 표준화 및 기간 필터링\n",
      "3. 데이터 탐색\n",
      "   - 기본 통계량 산출: 총매출, 평균, 최대/최소값\n",
      "   - 시계열 분석 준비: 날짜별 매출 추이 파악\n",
      "   - 카테고리별 분석: 상품군, 지점, 고객 구분별 매출\n",
      "4. 시각화 및 트렌드 분석\n",
      "   - 월별/주별 매출 그래프\n",
      "   - 카테고리별 매출 비중 차트\n",
      "   - 시간에 따른 매출 변화 추이\n",
      "5. 심층 분석\n",
      "   - 시즌성, 주기성 분석\n",
      "   - 고객 세그먼트별 매출 차이\n",
      "   - 제품 또는 서비스 별 수익성 분석\n",
      "6. 인사이트 도출 및 보고서 작성\n",
      "   - 주요 발견 내용 요약\n",
      "   - 매출 증대 전략 제안 가능 포인트 도출\n",
      "   - 향후 분석 방향 제시\n",
      "   \n",
      "이러한 단계별 구체적 분석 절차를 통해 2025년 전반기 매출 현황과 인사이트를 체계적으로 파악하실 수 있습니다. 추가적으로 원하시는 데이터 유형이나 세부 분석 목적이 있으면 알려 주세요.\n"
     ]
    }
   ],
   "source": [
    "#단발성 명령 수행 PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 클라이언트 요구사항을 분석해서 단계를 나눠주는 전문가입니다. \n",
    "사용자의 질문을 EDA 할 수 있도록 단계를 나눠 주세요.\n",
    "\n",
    "잘문 : {question}\n",
    "\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question':'이번 2025년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c8786d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^202^5^년^ 전^반^기^ 매^출^ 분석^을^ 위해^ E^DA^(^탐^색^적^ 데이터^ 분석^)^ 단^계를^ 다음^과^ 같이^ 나^눌^ 수^ 있습니다^:\n",
      "\n",
      "^1^.^ **^목^적^ 정의^ 및^ 요구^사항^ 파^악^**\n",
      "^  ^ -^ 분석^ 목표^ 명^확^화^ (^예^:^ 매^출^ 증^감^ 원^인^ 파^악^,^ 상품^별^·^지역^별^ 분석^ 등^)\n",
      "^  ^ -^ 기대^하는^ 인^사이트^ 및^ 활용^ 목적^ 정^리^\n",
      "\n",
      "^2^.^ **^데^이터^ 수^집^ 및^ 준비^**\n",
      "^  ^ -^ 데이터^ 소^스^ 확인^ (^영^업^ 데이터^,^ 거래^ 기록^,^ 고객^ 정보^ 등^)\n",
      "^  ^ -^ 데이터^ 수^집^ 수행^\n",
      "^  ^ -^ 데이터^ 적^재^ 및^ 저장^ 구조^ 파^악^\n",
      "\n",
      "^3^.^ **^데^이터^ 정^제^ 및^ 전^처^리^**\n",
      "^  ^ -^ 결^측^값^ 및^ 이상^치^ 처리^\n",
      "^  ^ -^ 데이터^ 형^식^ 통^일^ (^문^자^열^,^ 날짜^,^ 숫^자^ 등^)\n",
      "^  ^ -^ 필요한^ 열^ 선택^ 및^ 새^로^ 생성^ (^예^:^ 월^별^,^ 분^기^별^ 열^)\n",
      "\n",
      "^4^.^ **^기^초^ 데이터^ 분석^ 및^ 시^각^화^**\n",
      "^  ^ -^ 기본^ 통^계^ 검^토^ (^평^균^,^ 중앙^값^,^ 분^산^,^ 최대^/^최^소^값^ 등^)\n",
      "^  ^ -^ 전체^ 매^출^ 추^이^ 시^계^열^ 분석^\n",
      "^  ^ -^ 월^별^/^분^기^별^ 매^출^ 추^이^ 확인^\n",
      "^  ^ -^ 상품^별^·^지역^별^ 매^출^ 비^중^ 파^악^\n",
      "\n",
      "^5^.^ **^심^화^ 분석^**\n",
      "^  ^ -^ 고객^ 세^분^화^와^ 매^출^ 기^여^도^ 분석^\n",
      "^  ^ -^ 신규^·^중^장^기^ 고객^ 분석^\n",
      "^  ^ -^ 시즌^별^/^프로^모^션^별^ 매^출^ 영향^ 분석^\n",
      "\n",
      "^6^.^ **^인^사이트^ 도^출^ 및^ 보고^서^ 작성^**\n",
      "^  ^ -^ 핵^심^ 발견^사항^ 정^리^\n",
      "^  ^ -^ 시^각^자료^ 제작^ (^그래^프^,^ 차^트^)\n",
      "^  ^ -^ 분석^ 결과^를^ 바^탕^으로^ 전략^적^ 제^언^ 준비^\n",
      "\n",
      "^7^.^ **^추^가^ 분석^/^모^델^링^ 필요^시^ 검^토^**\n",
      "^  ^ -^ 매^출^ 예^측^ 모델^ 설^계^ 고려^\n",
      "^  ^ -^ 세^부^ 원^인^ 분석^ 및^ 가^설^ 검^증^\n",
      "\n",
      "^이^ 단계^별^로^ 진행^하면^,^ ^202^5^년^ 전^반^기^ 매^출^에^ 대한^ 깊^이^ 있는^ 이해^와^ 의미^ 있는^ 인^사이트^를^ 도^출^할^ 수^ 있습니다^.^^"
     ]
    }
   ],
   "source": [
    "#런어블 스티림.\n",
    "for token in chain.stream({'question':'이번 2025년 전반기 매출 분석'}): \n",
    "\n",
    "    print(token, end ='^', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c102f05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain은 자연어 처리(NLP) 애플리케이션 개발을 위한 프레임워크로, 언어 모델과 다양한 도구들을 쉽게 통합할 수 있도록 도와줍니다. 이를 통해 챗봇, 질문 응답 시스템 등 복잡한 인공지능 애플리케이션을 효율적으로 구축할 수 있습니다. 또한, 외부 데이터 소스와 연동하여 더욱 풍부한 정보를 제공하는 기능도 지원합니다.',\n",
       " 'Langchain은 자연어 처리(NLP) 애플리케이션 개발을 돕는 파이썬 라이브러리로, 다양한 언어 모델과 자연어 인터페이스를 쉽게 통합할 수 있게 해줍니다. 주로 대화형 에이전트, 질문답변 시스템, 데이터 분석 등에 활용되며, 데이터 소스와의 연결 및 기억 기능도 지원합니다. 이를 통해 복잡한 NLP 워크플로우를 간단하게 구축하고 배포할 수 있습니다.',\n",
       " 'Langchain은 자연어 처리 및 대화형 애플리케이션을 개발하기 위한 Python 라이브러리로, 다양한 언어 모델과 도구를 쉽게 통합할 수 있게 도와줍니다. 이를 통해 사용자들은 복잡한 대화 흐름, 데이터 연결, 및 API 연동 등을 간단하게 구축할 수 있습니다. 또한, Langchain은 텍스트 요약, 질의응답, 챗봇 개발 등 다양한 NLP 태스크에 활용될 수 있도록 설계되었습니다.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}에 대해서 3문장으로 설명해줘')\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "chain = prompt |llm | StrOutputParser()\n",
    "chain.batch([\n",
    " \n",
    "        {'topic': 'Langchain'},\n",
    "        {'topic': 'Langchain'},\n",
    "        {'topic': 'Langchain'},\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82385c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
