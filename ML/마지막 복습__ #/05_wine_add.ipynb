{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd17a28",
   "metadata": {},
   "source": [
    "# Descision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "wine = pd.read_csv('./wine.csv')\n",
    "wine.head()\n",
    "wine.info()\n",
    "wine.describe()\n",
    "\n",
    "# 1. 스케일이 다르다 (화이트와 레드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79283874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# 데이터 분리\n",
    "X= wine[['alcohol', 'sugar', 'pH']]\n",
    "y= wine['class'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스케일링 \n",
    "#스케일링 \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#스케일러 객체 생성 \n",
    "ss = StandardScaler()\n",
    "\n",
    "# 훈련 세트의 통계(평균, 표준편차)를 사용하여 스케일러를 학습시키고 , 훈련세트를 변환한다.(데이터 누수 방지)\n",
    "ss.fit(X_train) #오직 훈련 데이터에서만 수행해야함 , 테스트 정보가 학습과정에 유출되는  데이터 누수를 막기 위함 \n",
    "X_train_scaled= ss.transform(X_train)\n",
    "X_test_scaled= ss.transform(X_test)\n",
    "#표준화는  머신러닝 모델의 성능을 향상시키기 위해 특성의 스케일을 뭐처 주는 전처리 과정이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr= LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print('훈련점수: ', lr.score(X_train_scaled, y_train))\n",
    "print('테스트점수: ',lr.score(X_test_scaled, y_test))\n",
    "\n",
    "print(lr.classes_)\n",
    "lr.predict_proba(X_test_scaled[:5])\n",
    "\n",
    "print(lr.coef_, lr.intercept_)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_scaled, y_train)#학습 시킴\n",
    "\n",
    "print('훈련덤수: ', dt.score(X_train_scaled, y_train))\n",
    "print('테스트점수: ', dt.score(X_test_scaled, y_test))\n",
    "#지니가 말하는 것은 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39497b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plot_tree(dt, max_depth=2, filled=True, feature_names=['alcohol', 'sugar', 'pH']) #표시되는 숫자는 스케일링된 값이다.\n",
    "plt.show()\n",
    "#지니 불순도(순수도) 를 보고 R/W 의 비율을 알 수 있음. \n",
    "# 지니 불순도 1- (음성클래스비율 ^2+ 양성클래스비율^2) >> 0.5에 가까우면 분류가 잘 안된것 , 0이나오면 \n",
    "#-0.239 라는 기준은 지니 불순도를 최소화하는 방식으로 결정된다. 지니 불순도는 해당 노드에 포함된 클래스가 얼마나 섞여 있는지를 나타낸다 \n",
    "#샘플 5197개 중에서 R/W를 분류하고 그 과정을 반복한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 발생할 수 있는 문제: 너무 테스트 점수를 높이기 위해 하이퍼파라미터를 튜닝하는 것도 오버피팅이 아닐까? \n",
    "dt= DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "print('훈련덤수: ', dt.score(X_train_scaled, y_train))\n",
    "print('테스트점수: ', dt.score(X_test_scaled, y_test))\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plot_tree(dt, filled =True, feature_names=['alcohol', 'sugar', 'pH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1b5b0",
   "metadata": {},
   "source": [
    "- 언제 정지하느냐 \n",
    "1. 특성에 대해 다 시도해 보았을 때 \n",
    "2. 리프노드 ->순수노드 (예시 부정입학)\n",
    "3. 지니가 거의 고정이 될때 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff5150",
   "metadata": {},
   "source": [
    "## 교차 검증(Cross  Validation)\n",
    "\n",
    "테스트 셋 모델 검증 마지막 단계에서 한번만 확인. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d434c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련셋| 검증셋 | 테스트셋 \n",
    "# 80%              20%\n",
    "# 60%     20%      20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine= pd.read_csv('./wine.csv')\n",
    "X= wine[['alcohol', 'sugar', 'pH']]\n",
    "y = wine['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6471d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42) # 20%를 테스트 데이터로 사용하고 나머지를 훈련할 거다. \n",
    "#전체테스트 셋을 모델 의 최종 성능 평가에 사용, 학습과정에는 사용안됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub, X_val, y_sub, y_val = train_test_split(X, y,test_size=0.25, random_state=42)\n",
    "# 75는 훈련/검증에 쓰일 하위 데이터고, 25는 검증용 데이터이다.\n",
    "#모델 학습 중간과정에서 하이퍼파라미터 튜닝 및 모델 선택에 사용된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac40453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_sub, y_sub)\n",
    "print('훈련: ', dt.score(X_sub, y_sub))\n",
    "print('검증: ', dt.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#검증셋에 있는 것도 쪼개서 훈련이 가능한 교차검증 데이터의 8~90% 훈련해 볼 수 있음\n",
    "#k-fold cross validation(데이터를 쪼개서 훈련-검증 데이터를 바꿔가며 훈련진행-> 점수 평균)\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(dt, X_train, y_train )\n",
    "display(scores)\n",
    "print(np.mean(scores['test_score']))\n",
    "#score time은 훈련시간이고, fit은 학습시간 \n",
    "\n",
    "#그리드 서치 안에 포함된 값들을 출력한다. \n",
    "\"\"\"\n",
    "fit_time: 각 하이퍼 파라미터 조합에 대해 모델을 학습 (fit)하는데 걸린시간\n",
    "score_time: 교차검증 과정에서 모델이 predict/ score 하는 데 걸린시간(예측속도를 간접적으로 보여준다)\n",
    "test_score: 교차 검증 과정에서 얻은 점수(기본은 accuracy, 혹은 지정한 scoring 함수)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb700a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드 기본값 5가 아닌 다른 값을 쓰고 싶을 경우 (기본 교차 검증방식 커스터 마이징 )\n",
    "from sklearn.model_selection import StratifiedKFold ## 단순히 k개로 나누는게 아니라 \n",
    "# 클래스 비율(레이블 분포)를 유지하면서 나눔 \n",
    "#                                       접기 전에 최초 1회 셔플링    \n",
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_validate(dt, X_train, y_train, cv=splitter)\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7b695",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 튜닝\n",
    "1. GridSearch를 진행할 하이퍼 파라미터 선택\n",
    "2. 그리드 서치 수행(fit)\n",
    "3. 최적 조합을 찾고, gs 객체에 저장됨,\n",
    "4. 그리드 서치는 최상의 매개변수에서, 전체 훈련세트를 사용해 최종 모델을 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c67b33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_impurity_decrease': 0.0001} [0.86800067 0.86453617 0.86492226 0.86780891 0.86761605 0.86338306]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9615162593804117"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006],\n",
    "} ## 하이퍼파라미터 후보 값들 , 여러값으로 지정\n",
    "                  \n",
    "gs = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),  # 모델\n",
    "    param_grid=params,  # 확인할 하이퍼파라미터의 이름: 값들\n",
    "    n_jobs=-1,  # CPU 최대 코어\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train) #여기서 그리드서치가 실제로 동작함 \n",
    "\n",
    "# Grid Search 결과 가장 좋은 파라미터 조합으로 모델 만들기\n",
    "print(gs.best_params_, gs.cv_results_['mean_test_score']) #각 파라미터 조합별 평균 검증 성능 \n",
    "\n",
    "dt = gs.best_estimator_ #최적의 파라미터를 적용한 최종 모델\n",
    "dt.score(X_train, y_train) #과적합 여부를 보기 위해 X_test와 비교함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e24b0f",
   "metadata": {},
   "source": [
    "## 코드 요약 \n",
    "* GridSearchCV를 이용해서 \n",
    "    1. min_impurity_decrease 후보값들을 모두 테스트\n",
    "    2. 교차 검증으로 성능을 비교해서 가장 좋은 값(best_params_)을 찾은뒤 \n",
    "    3. 최적모델(best_estimator_)을 저장해서 성능을 평가 하는 과정 \n",
    "- 즉 , 의사결정트리 모델의 하이퍼파라미터 최적화 및 최적 모델 학습을 수행하는 코드였음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # 노드 분할을 위한 최소 불순도\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),\n",
    "    # 트리 깊이\n",
    "    'max_depth': range(5, 20, 1),\n",
    "    # 노드를 나누기 위한 최소 샘플 수\n",
    "    'min_samples_split': range(2, 100, 10),\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53678e1",
   "metadata": {},
   "source": [
    "## 코드 요약 \n",
    "의사결정트리의 하이퍼파라미터를 탐색해서 가장 좋은 조합을 찾는 과정 \n",
    "- min_impurity_decrease: 노드를 분할할지 결정하는 기준(작을수록 복잡한 트리임)\n",
    "- max_depth 트리의 최대 깊이 \n",
    "- min_samples_split: 노드를 나누기 위한 최소 샘플 수 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45087a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내부 교차검증 결과 가장 높은 평균 점수\n",
    "np.max(gs.cv_results_['mean_test_score'])\n",
    "\n",
    "# 모든 하이퍼파라미터 교차검증 끝에 찾은 학습이 끝난 최고의 모델\n",
    "dt_best = gs.best_estimator_\n",
    "# 로 아껴놨던 테스트 진행 -> 점수\n",
    "dt_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a72c13",
   "metadata": {},
   "source": [
    "코드요약\n",
    "- 교차검증으로 뽑힌 최적 모델(best_estimator_)을 아껴둔 진짜 테스트셋에 적용.\n",
    "- 이 테스트셋은 처음부터 훈련에 전혀 사용되지 않았기 때문에 최종 성능 검증(Generalization Test) 용으로 가장 공정함.\n",
    "- 여기서 얻는 점수가 실제 배포 후 성능을 가장 가깝게 예측하는 지표가 됨.\n",
    "궁금한 것 정리\n",
    "* 왜 마지막에 테스트셋을 쓰는가? \n",
    "- 그리드서치는 내부적으로 교차검증을 통해 성능이 좋은 하이퍼파라미터 조합을 찾음, \n",
    "- 교차 검증에 사용된 데이터는 모두 훈련 데이터(X_train, y_train) 안에서만 나눠 쓰는 것이다. \n",
    "- 교차 검증 점수는\" 훈련 데이터 기반\" 성능 일뿐 진짜 새로운 데이터에서 잘작동하는지 보장하지 않으므로 진짜 테스트셋에 적용해야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a563e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "# 주어진 범위에서 고르게 값을 뽑는다. (randint- > 정수, uniform -> 실수 )\n",
    "rgen= randint(0, 10)\n",
    "rgen.rvs(10)\n",
    "rgen.rvs(1000)\n",
    "\n",
    "np.unique(rgen.rvs(1000),return_counts= True)\n",
    "ugen= uniform(0,1)\n",
    "print(ugen.rvs(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea23553",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # 노드 분할을 위한 최소 불순도\n",
    "    'min_impurity_decrease': uniform(0.0001, 0.001),\n",
    "    # 트리 깊이\n",
    "    'max_depth': randint(20, 50),\n",
    "    # 노드를 나누기 위한 최소 샘플 수\n",
    "    'min_samples_split': randint(2, 25),\n",
    "    # 리프 노드 개수 최소값 \n",
    "    'min_samples_leaf': randint(1, 25)\n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "gs = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    params,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d871809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_\n",
    "dt = gs.best_estimator_\n",
    "\n",
    "print('최종 테스트 결과: ', dt.score(X_test, y_test))\n",
    "\n",
    "##테스트 점수에 맞출려고 하지말고, 범주안에서 얼머나 뽑을 지 범위도 자동으로 정해줌 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166703c7",
   "metadata": {},
   "source": [
    "# 추가 분석 시도 \n",
    "  분류문제 ->quality 점수를 특정 구간으로 나눠서 예측, 회귀 문제 -> quality점수를 그대로 수치 예측\n",
    "  ## 1. 회귀\n",
    "    - 선형회귀\n",
    "    - 릿지/라쏘 \n",
    "    - 의사결정나무 회귀:비선형 관계 포착\n",
    "    - 랜덤포레스트 회귀: 앙상블 성능향상 \n",
    "    - 그래디언트 부스팅:성능 최적화 \n",
    "    - KNN 회귀 \n",
    "## 2. 분류\n",
    "    - 로지스틱 회귀 \n",
    "    - KNN 분류\n",
    "    - 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7ad174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 타겟 변환 (범주화) : 클래스 불균형 고려 \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421505fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>11.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>9.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>12.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>11.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  sugar    pH  class\n",
       "0         9.4    1.9  3.51    0.0\n",
       "1         9.8    2.6  3.20    0.0\n",
       "2         9.8    2.3  3.26    0.0\n",
       "3         9.8    1.9  3.16    0.0\n",
       "4         9.4    1.9  3.51    0.0\n",
       "...       ...    ...   ...    ...\n",
       "6492     11.2    1.6  3.27    1.0\n",
       "6493      9.6    8.0  3.15    1.0\n",
       "6494      9.4    1.2  2.99    1.0\n",
       "6495     12.8    1.1  3.34    1.0\n",
       "6496     11.8    0.8  3.26    1.0\n",
       "\n",
       "[6497 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714183d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 데이터 불러오기 \n",
    "df = pd.read_csv('/Users/gim-yujin/Desktop/TIL/ML/wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e929828a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'quality'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'quality'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mquality_label\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquality\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(label_quality)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'quality'"
     ]
    }
   ],
   "source": [
    "# 2. 타겟 범주화 (3~4=Low, 5~6=Medium, 7~8=High)\n",
    "def label_quality(q):\n",
    "    if q <= 4:\n",
    "        return \"Low\"\n",
    "    elif q <= 6:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "df['quality_label'] = df['quality'].apply(label_quality)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
