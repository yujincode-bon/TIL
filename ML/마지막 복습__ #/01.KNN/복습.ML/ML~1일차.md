## 01. KNN 
### `01_knn_class (1).ipynb`: K-NN 분류 모델

이 파일은 K-NN을 **분류(Classification)** 문제에 적용하는 방법을 보여줍니다.

#### 1. 데이터 준비
* **`fish.csv`** 파일을 Pandas DataFrame으로 불러온 후, 넘파이 배열로 변환합니다.
* `fish_data` (특성: 농어의 길이, 높이, 너비)와 `fish_target` (종속 변수: 농어의 종류)으로 데이터를 분리합니다.
* `train_test_split`을 사용해 데이터를 훈련 세트와 테스트 세트로 나눕니다. 

#### 2. K-NN 모델 훈련 및 평가
* **`KNeighborsClassifier`** 모델을 생성하고, 훈련 데이터로 모델을 학습시킵니다.
* `n_neighbors=5`는 예측 시 가장 가까운 5개의 이웃을 참고하겠다는 의미입니다.
* `model.score()` 메서드를 이용해 **훈련 세트(0.932)**와 **테스트 세트(0.925)**에 대한 정확도 점수를 평가합니다. 두 점수가 모두 높고 비슷해 과적합 없이 모델이 잘 작동하고 있음을 보여줍니다.

#### 3. 예측 및 확률
* 새로운 데이터 `[[25, 10, 5]]`를 모델에 넣어 예측을 수행합니다. 
* `model.predict()`는 예측 결과를 출력하고, `model.predict_proba()`는 각 클래스(생선 종류)에 대한 예측 확률을 출력합니다.
* **핵심 개념:** K-NN 분류 모델은 새로운 데이터와 가장 가까운 K개의 이웃을 찾고, 그 이웃들의 **다수결 투표**를 통해 최종 클래스를 결정합니다. 예를 들어, 5개의 이웃 중 3개가 'Bream'이면 'Bream'으로 예측합니다.

#### 4. 하이퍼파라미터 튜닝
* `n_neighbors` 값을 1부터 49까지 변경하며 모델의 정확도를 평가합니다.
* 그래프를 통해 K값이 커질수록 정확도가 변하는 것을 시각적으로 확인합니다. 일반적으로 적절한 K값을 찾는 과정이 필요합니다.
* **핵심 개념:** `n_neighbors`와 같은 K-NN의 매개변수는 **하이퍼파라미터**로, 모델의 성능에 직접적인 영향을 미치므로 최적의 값을 찾는 튜닝 과정이 중요합니다.

---
## 02 REGRESSION 
### 파일 분석 및 요약

### `02_regression.ipynb`: K-NN 회귀 모델

이 파일은 K-NN을 **회귀(Regression)** 문제에 적용하는 방법을 보여줍니다.

#### 1. 데이터 준비
* **`perch.csv`** 파일과 `perch_weight` 배열을 준비합니다. `perch_data`는 농어의 길이, `perch_weight`는 농어의 무게입니다.
* `train_test_split`을 사용해 데이터를 훈련 세트와 테스트 세트로 나눕니다.

#### 2. K-NN 회귀 모델 훈련 및 평가
* **`KNeighborsRegressor`** 모델을 생성하고, 훈련 데이터로 모델을 학습시킵니다.
* **`lr.score()`** 메서드를 이용해 모델의 **$R^2$ 점수**를 평가합니다. 훈련 세트 점수(0.969)와 테스트 세트 점수(0.963)가 모두 높아, 모델이 데이터의 경향을 잘 예측하고 있음을 나타냅니다. 
* **핵심 개념:** K-NN 회귀 모델은 새로운 데이터와 가장 가까운 K개의 이웃을 찾고, 그 이웃들의 **종속 변수 값의 평균**을 예측값으로 사용합니다.

#### 3. 예측 및 시각화
* `model.predict()`를 사용하여 새로운 데이터 포인트 `[[50]]`에 대한 무게를 예측합니다.
* `plt.scatter()`와 `plt.plot()`를 사용하여 훈련 데이터와 예측 결과를 시각화합니다. 
* **핵심 개념:** 이 그래프는 새로운 데이터 포인트(x=50)에 대한 예측값(y=1033.0)이 가장 가까운 K(=3)개의 이웃들의 평균값임을 시각적으로 보여줍니다. 
* **주의점:** K-NN은 예측 범위 밖의 새로운 데이터에 대해서는 가장 가까운 이웃들의 평균값을 사용하기 때문에, 훈련 데이터의 범위를 벗어나는 데이터에 대한 예측은 한계가 있습니다.



## 03. 특성공학

### 궁금한 점 
**훈련 세트 점수(0.9903)**와 **테스트 세트 점수(0.9714)**가 모두 크게 향상된 것을 확인할 수 있습니다. >> 이경우에 과적합되었다고할 수 있나?
>> 점수값이 1에 가까워 상당히 높고, 훈련 점수와 테스트 점수가 매우 유사하여, 성능이 좋은 모델이라고 할 수 있고, 과적합없다고 볼 수 있음. 
----- 
### 파일 분석 및 요약

제공된 Jupyter Notebook 파일은 **특성 공학(Feature Engineering)**의 한 기법인 **다항 특성(Polynomial Features)**을 활용하여 선형 회귀 모델의 성능을 향상시키는 과정을 보여줍니다. 📉 이 과정은 훈련 데이터의 관계가 선형적이지 않을 때, 모델이 더 복잡한 패턴을 학습하도록 돕습니다.

---

### 코드 흐름 및 핵심 개념

#### 1. 데이터 준비
* **perch.csv** 파일을 불러와 **`perch_data`**와 **`perch_weight`** 변수에 저장합니다.
* `perch_data`는 농어의 길이, 높이, 너비와 같은 특성을 담고 있으며, `perch_weight`는 농어의 무게를 나타냅니다.
* `train_test_split`을 사용해 데이터를 **훈련 세트(`X_train`, `y_train`)**와 **테스트 세트(`X_test`, `y_test`)**로 나눕니다. `random_state=42`는 항상 동일한 분할 결과를 보장합니다.

#### 2. 단순 선형 회귀 모델 훈련 및 평가
* `LinearRegression` 모델을 생성하고, 원본 데이터(`X_train`, `y_train`)로 훈련시킵니다.
* **`lr.coef_`**와 **`lr.intercept_`**를 출력하여 모델이 학습한 계수(기울기)와 절편을 확인합니다.
* `lr.score`를 이용해 **훈련 세트(0.9559)**와 **테스트 세트(0.8796)**에 대한 $R^2$ 점수를 평가합니다. 이 점수는 모델이 데이터의 분산을 얼마나 잘 설명하는지 나타내며, 1에 가까울수록 성능이 좋습니다.
* **핵심 개념:** 이 단계는 데이터의 관계가 선형적이라고 가정하고 모델을 만들었을 때의 기본 성능을 보여줍니다. 🔍

#### 3. 다항 특성 생성 (특성 공학)
* `PolynomialFeatures`를 사용하여 기존 특성(`x0`, `x1`, `x2`)을 제곱하거나 서로 곱한 새로운 특성을 만듭니다. 예를 들어, `x0^2`, `x0 x1`, `x1^2` 등이 추가됩니다.
* `include_bias=False`는 절편에 해당하는 상수항(1)을 특성에 추가하지 않도록 설정합니다.
* `X_train_poly`와 `X_test_poly`는 이렇게 변환된 새로운 데이터셋입니다. `X_train_poly.shape`를 확인하면 특성의 개수가 원본 데이터(3개)에서 9개로 증가했음을 알 수 있습니다.

#### 4. 다항 선형 회귀 모델 훈련 및 평가
* **새로운 다항 특성 데이터셋**(`X_train_poly`, `X_test_poly`)을 사용하여 다시 `LinearRegression` 모델을 훈련시키고 평가합니다.
* **훈련 세트 점수(0.9903)**와 **테스트 세트 점수(0.9714)**가 모두 크게 향상된 것을 확인할 수 있습니다.
* **핵심 개념:** 이는 농어의 무게와 특성 사이의 관계가 단순한 선형 관계가 아니라 **곡선(비선형)** 형태에 가깝다는 것을 시사합니다.  다항 특성을 추가함으로써 모델이 이 비선형 관계를 더 잘 학습하게 된 것입니다. 👍

#### 5. 과대적합(Overfitting)의 위험성
* `PolynomialFeatures(degree=5, include_bias=False)`를 사용하여 **차수를 5로 높여** 더 많은 특성을 생성합니다.
* `lr.score(X_train_p5, y_train)` 결과는 훈련 데이터에 완벽하게 맞는 매우 높은 점수를 보이지만, `lr.score(X_test_p5, y_test)` 점수는 현저히 낮아집니다.
* **핵심 개념:** 이것은 모델이 훈련 데이터의 잡음까지 학습하여, 실제 새로운 데이터에 대한 예측 성능이 떨어지는 **과대적합**이 발생했음을 보여줍니다. 이는 모델의 복잡도가 지나치게 높아질 때 나타나는 일반적인 문제입니다.
* **결론:** 특성 공학은 모델 성능 향상에 유용하지만, **모델의 복잡도를 적절하게 조절**하는 것이 중요하며, 그렇지 않으면 과적합으로 이어질 수 있습니다. ⚠️